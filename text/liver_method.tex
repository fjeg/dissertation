In this study, we compare the performance of two widely used machine-learning methods to achieve this: logistic regression and L1-regularized logistic regression (LASSO). From these results, we can determine which semantic features are predicted by computational ones, and which computational features are the most useful for this purpose. Knowledge of which semantic features are not predicted well could lead to the development of new computational features for this purpose. Ultimately, prediction of semantic features from computational ones could lead to reduced variability in image interpretation.

\subsection{Semantic Features}
A radiologist annotated the ROI with the Electronic Physician's Annotation Device (ePAD; formerly iPAD) \cite{Napel:2010es, Rubin:2008uz}. The ePAD system is based on a controlled radiological vocabulary called RadLex to define semantic features \cite{Korenblum:2011gx, Langlotz:2006jn}, and enforces complete description of the required aspects of the visualized lesion. We extended the RadLex terminology to include a broader array of descriptive terms for this study that more comprehensively describe liver lesions. Each annotation resulted in the creation of a binary semantic feature vector of length 76 to indicate positive or negative observations.
Semantic features were not all equally likely and ranged widely in annotation frequency. The entropy of each semantic feature was measured using the binary entropy function in order to determine the distribution of positive versus negative observations. The binary entropy function is defined as:

\begin{align}
	H(X) = -p\log_2(p) - (1-p)\log_2(1-p)
\end{align}

Where:

\begin{align}
	p = \frac{\textrm{positive observations}}{\textrm{total observations}}
\end{align}

$H(X)$ ranges from 0 to 1, achieving a maximum when a semantic feature has an equal number of positive and negative observations~\cite{MacKay:2003wc}. To avoid degenerate classification cases, only features with entropy greater than 0.4 were considered for classification, creating a total 30 semantic features per lesion (Table \ref{table:semanticfeaturelist}).

\subimport{}{semantic_feature_table}

\clearpage
\subsection{Computational Features}
The pixel data within the segmented liver lesions were processed to quantify contrast, texture, boundary, and shape (Table \ref{table:compfeaturelist}). Each lesion's extracted computational features were concatenated into a 431-dimensional feature vector.

\subsubsection{Contrast Features}
2-element feature vector containing: (a) the proportion of pixels with intensity larger than 100 Hounsfield Units (HU) and (b) the difference in the mean intensity values for pixels inside the lesion and within a 5-pixel rim outside the liver lesion.

\subsubsection{Texture Features}
349-element feature vector containing: (a) 13-element gray-level histogram-based, including the 9-bin histogram itself, the low frequency coefficients of its 3-level Haar wavelet transform, the abscissa of its peak, entropy, and its variance~\cite{Strela:2002vq}, (b) 12-element Gabor features~\cite{Zhao:2005wb} including the mean of the Gabor energy in the frequency domain over 3 scales and 4 orientations in a total of 12 bins, and (c) 324-element Daubechies features with the dominant sub-band in a 2-scale Daubechies wavelet transform.

\subsubsection{Margin Sharpness Features}
61-element feature vector computed as follows: (a) We recorded the image intensity values along normals to the lesion contour at multiple points and then fit a sigmoid function to these values.  Two parameters for the fitted sigmoid, scale and window, were used to characterize each line segment. The scale measures the difference in intensities outside and inside the lesion, and the window measures the transition from the liver lesion to the surrounding normal liver at the boundary. Two 30-bin histograms for the scale and window parameters were then created to form a 60-element feature vector. (b) We also recorded the number of modes in the histogram of all pixels recorded from each normal.

\subsubsection{Shape Features}
19-element feature vector containing: (a) Compactness ~\cite{Duda:1973ul}. (b) Roughness~\cite{Kilday:2002wp}. (c) Local area integral invariant descriptor including the mean and standard deviation for 5 different scales~\cite{Hong:2006ti,Manay:2006un}. (d) Radial distance signatures including mean and standard deviation~\cite{MRangayyan:2005td}.

\subimport{}{computational_feature_table}

\subsection{Classification}
Logistic regression was used to calculate the probability of a computational feature vector representing a positive or negative semantic feature. In order to mitigate the potential for over-fitting due to a large number of predictors (431 computational features) compared to data points (79 lesions), we also used L1-regularization \cite{Tibshirani:1996wb} to weight features given sparsity in the computational feature set.
