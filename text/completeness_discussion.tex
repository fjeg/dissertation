I described a method to quantify how incomplete the content is in a mammography report. I then presented an algorithm to measure this value in a computationally tractable manner. Finally, I showed that this incompleteness score is a strong indicator of errors in mammography interpretation. Implementation of this metric during mammography reporting time could provide a useful real-time feedback to radiologists to indicate possible errors.

\subsection{The benefits of complete reports}
Reporting in mammography is a labor intensive but critically important task for results communication. Though there is pressure for radiologists to expend their efforts efficiently, we show that poor report quality (measured by our incompleteness score) is a marker for interpretation errors. This result might stem from a few different causes. The causal explanation is that poor interpretation leads to poor reports. In this case, a radiologist might have not seen a relevant descriptor in the image or neglected to highlight its importance. Another possibility is that incomplete reporting is a function of available time. When required to read large volumes of images, speed may decrease accuracy. In this case, a practitioner producing brief or incomplete reports may also be spending less time interpreting the image. A third possibility is that the process of reporting improves diagnosis by requiring radiologists to reason about their diagnosis. Thus, individuals who do not spend as much time on their reports do not go through the same formal thinking process. For future work, we will consult breast imaging radiologists on cases that were correctly classified as erroneous to see if humans can also identify when poor reporting leads to mis-diagnosis. If this is the case, we can begin to discover reporting practices that reduce error rates.

\subsection{Limitations of this study}
Though the system I present shows promising results with regards to predicting radiological errors, it does have some shortcomings. The use of an approximate algorithm to estimate the incompleteness score allows for some degree of error. I correct for this by using a large number of samples with respect to the number of hidden variables, but unfortunately, it is difficult to empirically evaluate my system as calculating the exact incompleteness score is prohibitively expensive with regards to computational time. For future work, I will evaluate alternative approaches for measuring incompleteness. Another issue with our system is that it does not actually correct the errors in interpretation or give any constructive feedback. So although the system can potentially reduce the amount of errors by  ~20\%, I have not shown which of these reports would actually be corrected. The only way to truly ascertain the benefit of this alert system is through a clinical trial. Finally, this study was designed to be descriptive rather than predictive, so I did not measure classification results with an optimal cutoff in a third held-out test set. Thus, the results will be overly-optimistic in terms of error-prediction. In the future, I plan to implement our algorithm on faster cluster computers, which will allow me to perform a thorough cross-validation analysis to obtain better accuracy measurements. 

\subsection{Extension to other domains}
This methodology could be extend to any domain that uses expensive information to make threshold-based decisions. All this system requires is a generative model linking descriptors to diagnosis and a method to sample from this model. It is straightforward to implement this in any medical domain where testing can be a costly and/or risky task. Not only can this method improve diagnostic accuracy, but it inherently rewards good, thorough reporting practices. This is beneficial for patients and researchers alike.
