Radiological analysis and interpretation of liver lesions in CT images requires that the radiologist report on observations about findings.
These observations act as human-derived \emph{semantic features} of the image.
Semantic features allow radiologists to make their observations and interpretation explicit as well as machine-accessible.
These data can be fed as input to decision-support systems to aid in diagnosis of liver lesions.
Content-based image retrieval systems make use of semantic features to retrieve images by similarity \cite{Napel:2010vb} and lead to lead to accurate diagnoses of liver tumor types from CT images \cite{Korenblum:2011gx}.
In order to facilitate the use of semantic features, radiological tools such as the ePAD (formerly iPad) have been implemented with the purpose of recording these annotations \cite{Rubin:2008uz}.
Despite their extreme value, semantic features are valuable only when they are correct.
To date, there are no systems to verify whether the radiologist has made mistakes in reporting these features in liver lesions.


\begin{figure}[h]
	\centering
	\includegraphics[width=1\linewidth]{correctness_diagram.pdf}
	\caption[Overview of the the annotation verification system]{An image enters the system and is routed to a radiologist. They delineate a region of interest in the image. Then the system analyzes calculates computational image features while the radiologist concurrently creates semantic features. The system then predicts the semantic features generated by the radiologist to predict error.}
	\label{fig:correctness_diagram}
\end{figure}

In this study, I frame annotation verification as a classification problem to predict semantic features from image data.
I performed this experiment using a database of CT scans of liver lesions and their associated descriptors.
I focus on this data set because of its high quality images and ground-truth annotations by expert radiologists.
Such image data sets are not as readily available for mammography, though these methods are generalizable for any image annotation task \cite{Deselaers:2008gk}.
I follow a traditional machine-learning approach: extract computationally-derived features from training images, use these features along with their semantic labels to train a classifier, and evaluate this classifier on held-out data (Figure \ref{fig:correctness_diagram}). 
I use computationally-derived features that can be computed directly from the image's pixel values to predict the presence of specific semantic features by building upon previous digital image processing techniques to extract meaningful features indicative of lesion attenuation, texture, edge and shape \cite{Strela:2002vq,Zhao:2005wb,Hong:2006ti,Manay:2006un,MRangayyan:2005td,Xu:2012bh}.
I then compare the performance of two widely used machine-learning methods to do this prediction: logistic regression and L1-regularized logistic regression (LASSO).
From these results, I determine which semantic features are predicted by computational ones, and which computational features are the most useful for this purpose.
Knowledge of which semantic features are not predicted well could lead to the development of new computational features for this purpose.
Ultimately, prediction of semantic features from computational ones could lead to reduced variability in image interpretation.




